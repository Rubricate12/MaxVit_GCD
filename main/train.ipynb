{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import timm\n",
    "import torch\n",
    "import zipfile,os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_zip = '/DATA/ai lab/gcdData/GCD.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/DATA/ai lab')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/DATA/ai lab/GCD/train\n"
     ]
    }
   ],
   "source": [
    "train_dir = '/DATA/ai lab/GCD/train'\n",
    "test_dir = '/DATA/ai lab/GCD/test'\n",
    "\n",
    "os.listdir('/DATA/ai lab/GCD/train')\n",
    "print(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "    'maxvit_tiny_tf_224.in1k',\n",
    "    pretrained=True,\n",
    "    num_classes=7,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_dir = Path(train_dir)\n",
    "\n",
    "for img_path in train_dir.rglob(\"*.*\"):  # Recursively find all files\n",
    "    if img_path.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:  # Check for valid image extensions\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Open the image and convert to RGB\n",
    "        img_tensor = transforms(img).unsqueeze(0)  # Preprocess and add batch dimension\n",
    "\n",
    "        # Pass the image through the model\n",
    "        output = model.forward_features(transforms(img_tensor))\n",
    "\n",
    "        print(f\"Processed {img_path}: Output Shape - {output[-1].shape if isinstance(output, list) else output.shape}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/', 't']\n",
      "['r', 'A']\n",
      "[' ', 'a']\n",
      "['/', 'C']\n",
      "['/', 'T']\n",
      "['n', 'G']\n",
      "['l', 'D']\n",
      "['a', '/']\n",
      "['a', 'A']\n",
      "['i', 'D']\n",
      "['b', 'i']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for data in train_loader:\n",
    "    print(data)  # This will show you the structure of the data being returned\n",
    "    inputs, targets = data  # Unpack only if it has the correct structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()  \u001b[38;5;66;03m# Set the model to training mode\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     18\u001b[0m         inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Move to device\u001b[39;00m\n\u001b[0;32m     20\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Zero the gradients\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assuming you have a DataLoader for your training data\n",
    "train_loader = DataLoader(train_dir, batch_size=2, shuffle=True)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 20\n",
    "# Training loop\n",
    "model.train()  # Set the model to training mode\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)  # Move to device\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, targets)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# After training, you can evaluate the model as you did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ImageFolder(root=test_dir, transform=transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 4. Define testing loop\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "all_targets = []\n",
    "all_preds = []\n",
    "\n",
    "'''\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    for inputs, targets in test_loader:\n",
    "        # Perform forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Get predicted class indices\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        \n",
    "        # Compare predictions with ground truth\n",
    "        correct_predictions += (preds == targets).sum().item()\n",
    "        total_samples += targets.size(0)\n",
    "        \n",
    "        # Store predictions and labels for metrics\n",
    "        all_targets.extend(targets.tolist())\n",
    "        all_preds.extend(preds.tolist())\n",
    "'''\n",
    "# Perform forward pass\n",
    "outputs = model(inputs)\n",
    "        \n",
    "# Get predicted class indices\n",
    "_, preds = torch.max(outputs, dim=1)\n",
    "        \n",
    "# Compare predictions with ground truth\n",
    "correct_predictions += (preds == targets).sum().item()\n",
    "total_samples += targets.size(0)\n",
    "        \n",
    "# Store predictions and labels for metrics\n",
    "all_targets.extend(targets.tolist())\n",
    "all_preds.extend(preds.tolist())        \n",
    "\n",
    "accuracy = accuracy_score(all_targets, all_preds)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
